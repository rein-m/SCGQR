{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_data(ticker):\n",
    "    data = yf.download(ticker, start=\"2022-01-01\", end=\"2024-01-01\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather Data - use S&P 500 stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m sectors \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m table\u001b[38;5;241m.\u001b[39mfindAll(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtr\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m---> 11\u001b[0m     ticker \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfindAll\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     12\u001b[0m     company_name \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mfindAll(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtd\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     13\u001b[0m     sector \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mfindAll(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtd\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Fetch the list of S&P 500 companies from Wikipedia\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "resp = requests.get(url)\n",
    "soup = BeautifulSoup(resp.text, 'lxml')\n",
    "table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "\n",
    "tickers = []\n",
    "company_names = []\n",
    "sectors = []\n",
    "for row in table.findAll('tr')[1:]:\n",
    "    ticker = row.findAll('td')[0].text.strip()\n",
    "    company_name = row.findAll('td')[1].text.strip()\n",
    "    sector = row.findAll('td')[3].text.strip()\n",
    "    tickers.append(ticker)\n",
    "    company_names.append(company_name)\n",
    "    sectors.append(sector)\n",
    "\n",
    "# Create a DataFrame\n",
    "sp500 = pd.DataFrame({'Ticker': tickers, 'Company': company_names, 'Sector': sectors})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch financial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists to store data\n",
    "revenues = []\n",
    "market_caps = []\n",
    "betas = []\n",
    "\n",
    "for ticker in sp500['Ticker']:\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        \n",
    "        # Get total revenue from quarterly financials\n",
    "        quarterly_financials = stock.quarterly_financials\n",
    "        revenue = quarterly_financials.loc['Total Revenue'].sum()\n",
    "        revenues.append(revenue)\n",
    "        \n",
    "        # Get market cap and beta\n",
    "        info = stock.info\n",
    "        market_cap = info.get('marketCap', np.nan)\n",
    "        beta = info.get('beta', np.nan)\n",
    "        market_caps.append(market_cap)\n",
    "        betas.append(beta)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker}: {e}\")\n",
    "        revenues.append(np.nan)\n",
    "        market_caps.append(np.nan)\n",
    "        betas.append(np.nan)\n",
    "\n",
    "sp500['Revenue'] = revenues\n",
    "sp500['MarketCap'] = market_caps\n",
    "sp500['Beta'] = betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning/handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with NaNs in Revenue, MarketCap, or Beta\n",
    "sp500_clean = sp500.dropna(subset=['Revenue', 'MarketCap', 'Beta'])\n",
    "\n",
    "#categorize by market cap\n",
    "# Define market cap categories\n",
    "def categorize_market_cap(market_cap):\n",
    "    if market_cap >= 10e9:\n",
    "        return 'Large Cap'\n",
    "    elif market_cap >= 2e9:\n",
    "        return 'Mid Cap'\n",
    "    else:\n",
    "        return 'Small Cap'\n",
    "\n",
    "# Apply the categorization\n",
    "sp500_clean['MarketCapCategory'] = sp500_clean['MarketCap'].apply(categorize_market_cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering implementation (define clustering function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_market_cap_category(df, category):\n",
    "    df_category = df[df['MarketCapCategory'] == category]\n",
    "    # Use Beta and Revenue as features\n",
    "    X = df_category[['Beta', 'Revenue']].values\n",
    "    \n",
    "    # Handle any remaining NaNs\n",
    "    X = X[~np.isnan(X).any(axis=1)]\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Determine optimal number of clusters\n",
    "    sse = []\n",
    "    silhouette_scores = []\n",
    "    K = range(2, 10)\n",
    "    for k in K:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        kmeans.fit(X_scaled)\n",
    "        sse.append(kmeans.inertia_)\n",
    "        silhouette_avg = silhouette_score(X_scaled, kmeans.labels_)\n",
    "        silhouette_scores.append(silhouette_avg)\n",
    "    \n",
    "    # Plot elbow method and silhouette scores\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(K, sse, 'bx-')\n",
    "    plt.xlabel('Number of Clusters (k)')\n",
    "    plt.ylabel('Sum of Squared Errors')\n",
    "    plt.title(f'Elbow Method for {category}')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(K, silhouette_scores, 'bx-')\n",
    "    plt.xlabel('Number of Clusters (k)')\n",
    "    plt.ylabel('Silhouette Score')\n",
    "    plt.title(f'Silhouette Analysis for {category}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Choose optimal k (e.g., k with max silhouette score)\n",
    "    optimal_k = K[silhouette_scores.index(max(silhouette_scores))]\n",
    "    print(f\"Optimal number of clusters for {category}: {optimal_k}\")\n",
    "    \n",
    "    # Apply k-means with optimal k\n",
    "    kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "    labels = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    # Add labels to original DataFrame\n",
    "    df_category = df_category.iloc[~np.isnan(X).any(axis=1), :].copy()\n",
    "    df_category['Cluster'] = labels\n",
    "    \n",
    "    return df_category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply Clustering to each market cap category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply clustering to Large Cap\n",
    "df_large_cap = cluster_market_cap_category(sp500_clean, 'Large Cap')\n",
    "\n",
    "# Apply clustering to Mid Cap\n",
    "df_mid_cap = cluster_market_cap_category(sp500_clean, 'Mid Cap')\n",
    "\n",
    "# If there are Small Cap companies, apply clustering\n",
    "if 'Small Cap' in sp500_clean['MarketCapCategory'].unique():\n",
    "    df_small_cap = cluster_market_cap_category(sp500_clean, 'Small Cap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization/Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine clustered data\n",
    "clustered_data = pd.concat([df_large_cap, df_mid_cap], ignore_index=True)\n",
    "#plot data / visualize data\n",
    "def plot_clusters(df_category):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(data=df_category, x='Revenue', y='Beta', hue='Cluster', palette='Set1')\n",
    "    plt.title(f\"Clusters in {df_category['MarketCapCategory'].iloc[0]} Category\")\n",
    "    plt.xlabel('Revenue (Standardized)')\n",
    "    plt.ylabel('Beta (Standardized)')\n",
    "    plt.show()\n",
    "\n",
    "#plot for large market cap companies\n",
    "plot_clusters(df_large_cap)\n",
    "#midcap\n",
    "plot_clusters(df_mid_cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_profiles(df_category):\n",
    "    clusters = df_category['Cluster'].unique()\n",
    "    for cluster in clusters:\n",
    "        print(f\"\\nCluster {cluster} in {df_category['MarketCapCategory'].iloc[0]}:\")\n",
    "        cluster_df = df_category[df_category['Cluster'] == cluster]\n",
    "        print(\"Statistical Summary:\")\n",
    "        print(cluster_df[['Revenue', 'Beta']].describe())\n",
    "        print(\"\\nRepresentative Companies:\")\n",
    "        print(cluster_df[['Ticker', 'Company']].head())\n",
    "        \n",
    "#cluster profiles for large cap\n",
    "cluster_profiles(df_large_cap)\n",
    "#cluster profiles for mid cap\n",
    "cluster_profiles(df_mid_cap)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nelonmelon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
